<!DOCTYPE html>
<html>
<head>
  <!-- Meta -->
  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0">
  <meta name="description" content="Governing ID: A Framework for Evaluation of Digital Identity | Digital Identities: Design and Uses | A project of the Centre for Internet and Society, India, supported by Omidyar Network" />
  <!-- Title + CSS + Favicon -->
  <title>Digital Identities: Design and Uses</title>
  <link rel="stylesheet" type="text/css" href="css/semantic.min.css">
  <link rel="stylesheet" type="text/css" href="css/style.css">
  <link rel="stylesheet" type="text/css" href="css/post.css">
  <link rel="shortcut icon" type="image/x-icon" href="img/favicon.ico" />
  <!-- Font Awesome -->
  <script src="https://kit.fontawesome.com/4c415b9185.js" crossorigin="anonymous"></script>
</head>
<body>
  <!-- Top Navigation Bar -->
  <div class="green nav-top">
    <div class="ui container">
      <a href="index.html">Home</a> / <a href="index.html#governingID">Governing ID</a> / <a href="index.html#maps">Exploratory Research Maps</a> / <a href="index.html#method">Methodology</a> / <a href="index.html#blog">Blog</a>
    </div>
  </div>
  <!-- Header -->
  <div class="gray">
    <div class="ui fluid container banner">
      <div class="banner-image"></div>
    </div>
  </div>
  <div class="ui container">
    <div class="site-title">
      <h1>Digital Identities</h1>
      <h2>Design and Uses</h2>
    </div>
    <div class="site-desc">
      <p>A project of the Centre for Internet and Society, India<br/>Supported by Omidyar Network</p>
    </div>
  </div>
  <!-- Content -->
  <div class="white">
    <div class="ui container two column stackable grid">
      <div class="six wide column">
      </div>
      <div class="ten wide column post-title">
        <h2>Governing ID: A Framework for Evaluation of Digital Identity</h2>
      </div>
      <div class="five wide column meta">
        <p><strong>Janaury 22, 2020</strong></p>
        <p><em>Research and Writing by</em> Vrinda Bhandari, Shruti Trikanad <em>and</em> Amber Sinha<br/>
          <em>Review by</em> Kaliya Young, Yesha Tshering Paul<br/><em>and</em> Sunil Abraham</p>
        <p><a href="docs/CIS_DigitalID_EvaluationFrameworkDraft02_2020.01.pdf" target="_blank">Download as PDF</a><br/>
          Watch the <a href="https://www.youtube.com/watch?v=zHKRgNbP4R0" target="_blank">introductory video</a><br/>
		  For a five-minute summary, <a href="introducing-evaluation-framework-02.html" target="_blank">read this blogpost</a></p>
        <p>An early draft of the framework is available <a href="evaluation-framework-01.html" target="_blank">here</a></p>
      </div>
      <div class="one wide column" id="empty">
      </div>
      <div class="ten wide column content">
        <p>As governments across the globe implement new and foundational digital identification systems (Digital ID), or modernize existing ID programs, there is an urgent need for more research and discussion about appropriate uses of Digital ID systems. This significant momentum for creating Digital ID has been accompanied with concerns about privacy, surveillance and exclusion harms of state-issued Digital IDs in several parts of the world, resulting in campaigns and litigations in countries, such as UK, India, Kenya, and Jamaica. Given the sweeping range of considerations required to evaluate Digital ID projects, it is necessary to formulate evaluation frameworks that can be used for this purpose.</p>
        <p>This work began with the question of what the appropriate uses of Digital ID can be, but through the research process, it became clear that the question of use cannot be divorced from the fundamental attributes of Digital ID systems and their governance structures. This framework provides tests, which can be used to evaluate the governance of Digital ID across jurisdictions, as well as determine whether a particular use of Digital ID is legitimate. Through three kinds of checks — Rule of Law tests, Rights based tests, and Risks based tests — this scheme is a ready guide for evaluation of Digital ID.</p>
      </div>
      <div class="sixteen wide column break">
      </div>
      <div class="five wide column meta">
        <h3>Rule of Law Tests</h3>
      </div>
      <div class="one wide column" id="empty">
      </div>
      <div class="ten wide column content">
		<p>The rise of Digital ID, and the opportunities they present, both for public and private actors, have in the past resulted in hasteful implementations and adoptions. This does not allow for sufficient deliberation to lead to governance mechanisms. Below are the most <em>basic</em> tests to ensure that a rule of law framework exists to govern the use of ID —</p>
      </div>
      <div class="five wide column meta">
        <h3>1.1</h3>
      </div>
      <div class="one wide column" id="empty">
      </div>
      <div class="ten wide column content">
        <h6>Legislative Mandate</h6>
		<h4>Is the project backed by a validly enacted law? Does the law amount to excessive delegation?</h4>
		<p>Digital ID, by its nature, will entail greater collection and generation of personally identifiable information, and privacy risks, which arise from it. Any such restrictions to the fundamental right to privacy must be prescribed by law in the form of a publicly available legislative act. Other forms of regulation, such as executive ordinance, only meet this requirement in limited ways. </p>
		<p class="indent">A validly enacted law has three components: (i) it should be passed by the Legislature, and not the Executive<sup class="superscript"><a href="#fn1">1</a></sup><a name="ref1"></a>&thinsp;; (ii) it should be accessible and foreseeable — this is to ensure the ‘quality of law’; and (iii) it should be clear and precise — this is to limit the scope of discretion. Each of these three legal requirements is explained in some detail below —</p>
      </div>
      <div class="five wide column meta">
        <h4>(i)</h4>
      </div>
      <div class="one wide column" id="empty">
      </div>
      <div class="ten wide column content">
        <h5>Legality</h5>
		<p>By its very nature, the collection, storage, and use of personally identifiable information through a Digital ID — especially if it has any mandatory requirements of identification, authentication, or authorisation — is likely to violate the right to privacy of the individual and affect their right to free speech, particularly as it leads to a chilling effect.<sup class="superscript"><a href="#fn2">2</a></sup><a name="ref2"></a> These concerns are exacerbated if the Digital ID is meant as a single online identity, that will more or less replace the use of existing functional identities, as was the case with several national identity programmes. </p>
		<p class="indent">The rule of law requires that every act by the State or by its officers must, if it is to operate to the prejudice of any person, be supported by some legislative authority.<sup class="superscript"><a href="#fn3">3</a></sup><a name="ref3"></a> There should be ‘a law,’ having statutory force and not a mere executive or departmental instruction.<sup class="superscript"><a href="#fn4">4</a></sup><a name="ref4"></a></p>
		<p class="indent">Thus, to pass constitutional muster, this infringement of a fundamental right or the invasion of life and personal liberty must be sanctioned by a law, having statutory force, enacted by the appropriate legislative body. This is the first prong of the proportionality test, as has been accepted key jurisdictions such as India,<sup class="superscript"><a href="#fn5">5</a></sup><a name="ref5"></a> UK,<sup class="superscript"><a href="#fn6">6</a></sup><a name="ref6"></a>  Canada,<sup class="superscript"><a href="#fn7">7</a></sup><a name="ref7"></a> South Africa,<sup class="superscript"><a href="#fn8">8</a></sup><a name="ref8"></a> and by the European Court of Human Rights (‘ECtHR’) (as part of Article 8(2), European Charter of Human Rights’ requirement of ‘accordance with law’).<sup class="superscript"><a href="#fn9">9</a></sup><a name="ref9"></a></p>
      </div>
      <div class="five wide column meta">
        <h4>(ii)</h4>
      </div>
      <div class="one wide column" id="empty">
      </div>
      <div class="ten wide column content">
		<h5>Quality of Law</h5>
		<p>Some courts have interpreted the legal standard of ‘in accordance with law’ as requiring ‘quality of law’, namely that the law is “accessible to the person concerned, who must, moreover, be able to foresee its consequences for him, and compatible with the rule of law.”&thinsp;<sup class="superscript"><a href="#fn10">10</a></sup><a name="ref10"></a> In this definition, foreseeability would require that the law be “sufficiently clear in its terms to give citizens an adequate indication of the conditions and circumstances in which the authorities are empowered to resort to any such measures”.<sup class="superscript"><a href="#fn11">11</a></sup><a name="ref11"></a> While absolute certainty is not required as part of the ‘foreseeability’ requirement,<sup class="superscript"><a href="#fn12">12</a></sup><a name="ref12"></a> the rationale behind introducing these requirements is to prevent any arbitrary interference with fundamental rights by the State.<sup class="superscript"><a href="#fn13">13</a></sup><a name="ref13"></a></p>
		</div>
      <div class="five wide column meta">
        <h4>(iii)</h4>
      </div>
      <div class="one wide column" id="empty">
      </div>
      <div class="ten wide column content">
        <h5>Clarity and Precision of Law</h5>
		<p>The requirement of clarity and precision aims to make the law specific, so as to limit its scope. By regulating the exercise of discretion, it serves as an effective guarantee against abuse.<sup class="superscript"><a href="#fn14">14</a></sup><a name="ref14"></a></p>
		<p class="indent">In this context, the relevant factors to ensure legislative quality are the quality of the substantive content of the law governing Digital ID, its form and language, the manner in which it was implemented, and its ‘effectiveness’, i.e. its ability to produce the desired regulatory results.<sup class="superscript"><a href="#fn15">15</a></sup><a name="ref15"></a></p>
		<p class="indent">Further, it is a settled principle that a law is void if it is vague,<sup class="superscript"><a href="#fn16">16</a></sup><a name="ref16"></a> and a vague law is one which impermissibly or excessively delegates basic policy matters to the executive, or if the Legislature abdicate its duty of laying down adequate guidelines for the exercise of Executive power.<sup class="superscript"><a href="#fn17">17</a></sup><a name="ref17"></a> This can lead to arbitrary and discriminatory application of the law. In the context of a Digital ID law, the factors to consider are whether basic policy matters of collection, storage, use, and sharing of the personally-identifiable information have been delegated to a rule-making body that is part of the Executive.</p>
      </div>
      <div class="five wide column meta">
        <h3>1.2</h3>
      </div>
      <div class="one wide column" id="empty">
      </div>
      <div class="ten wide column content">
        <h6>Legitimate Aim</h6>
        <h4>Does the law have a ‘legitimate aim?’ Are all purposes flowing from a ‘legitimate aim’ identified in the valid law?</h4>
		<p>All the purposes for use of Digital ID thus, must correspond to a legitimate aim identified in the valid law.<sup class="superscript"><a href="#fn18">18</a></sup><a name="ref18"></a> The ECtHR has held that this legitimate aim should be “necessary in a democratic society,”&thinsp;<sup class="superscript"><a href="#fn19">19</a></sup><a name="ref19"></a> i.e., it must answer a “pressing social need.” It should not based merely on political expediency.<sup class="superscript"><a href="#fn20">20</a></sup><a name="ref20"></a></p>
		<p class="indent">In the context of a Digital ID, some illustrations of a ‘legitimate aim’ may be “in the interests of national security, public safety or the economic well-being of the country, for the prevention of disorder or crime, for the protection of health or morals, or for the protection of the rights and freedoms of others.”&thinsp;<sup class="superscript"><a href="#fn21">21</a></sup><a name="ref21"></a> The burden of proof in such cases, must be on the State to demonstrate the legitimate aim of the proposed law.<sup class="superscript"><a href="#fn22">22</a></sup><a name="ref22"></a> The only overarching requirement of the ‘legitimate aim’ standard is that it should not operate in a manner that discriminates on the basis of race, colour, sex, language, religion, political or other opinion, national or social origin, property, birth or other status.<sup class="superscript"><a href="#fn23">23</a></sup><a name="ref23"></a></p>
		<p class="indent">However, the legitimate aim is only one part of the proportionality test; any law governing Digital ID will still have to pass the proportionality test, which will be discussed below.</p>
      </div>
      <div class="five wide column meta">
        <h3>1.3</h3>
      </div>
      <div class="one wide column" id="empty">
      </div>
      <div class="ten wide column content">
        <h6>Defining Actors and Purposes</h6>
        <h4>Does the law clearly specify the actors and the purposes that would flow from the legitimate aim?</h4>
		<p>The legitimate aims for Digital ID must be identified in the law governing the project. Key vectors for determining the legitimacy of aims for such projects are the actors who use Digital ID, and the purposes for which Digital ID must be used.</p>
      </div>
      <div class="five wide column meta">
        <h4>(i)</h4>
      </div>
      <div class="one wide column" id="empty">
      </div>
      <div class="ten wide column content">
        <h5>Actors</h5>
    	<p>The law must clearly specify the actors, or a category of actors who may use the Digital ID. Actors include both the State and private actors; entities who may use the Digital ID, and agencies and databases to whom it may be connected in any way.</p>
		<p class="indent">Privacy serves as a restraint on the power of the government and private entities.<sup class="superscript"><a href="#fn24">24</a></sup><a name="ref24"></a> Consequently, the Digital ID law would also have to clarify whether — keeping in mind the legitimate aim of the Digital ID and whether it was mandating the use of the ID to access any service — it would apply <em>equally</em> to State and private actors.</p>
		<p class="indent">There has been limited examination of Digital ID by the courts, keeping in mind these principles. For instance, in India, in <em>K.S. Puttaswamy v Union of India (II)</em>&thinsp;<sup class="superscript"><a href="#fn25">25</a></sup><a name="ref25"></a> (“Aadhaar Judgment”) the court broadly struck down the use of the Digital ID programme by the private sector as being unconstitutional and disproportionate, enabling ‘commercial exploitation’ of biometric and demographic information by private parties, and due to concerns of possible profiling.<sup class="superscript"><a href="#fn26">26</a></sup><a name="ref26"></a> <sup class="superscript"><a href="#fn27">27</a></sup><a name="ref27"></a> It is worth noting that more than the focus of private and public actors, how digital identity is used is important. While we have had limited experience with digital identification systems, private use of other identification programmes has also been regulated. In the US, states such as Alaska, Kansas, Maine, New Mexico and Rhode Island either restrict the solicitation of Social Security Numbers or prohibit denying goods and services to an individual who declines to give their Social Security Number by private parties.<sup class="superscript"><a href="#fn28">28</a></sup><a name="ref28"></a> </p>
		<p class="indent">In light of the unresolved questions around private sector involvement in Digital ID, we believe that any law governing Digital ID should make clear (i) if and how private entities can use the Digital ID infrastructure created by the State? (ii) if so, can they mandate the use of a Digital ID to get access to private services such as banking and telecom? (iii) is the private sector’s use of the Digital ID and its surrounding infrastructure fulfilling the legitimate aim of the law and the legitimate purpose of using the ID? and (iv) if private sector entities will be held to the same standards of accountability as the State.</p>
      </div>
      <div class="five wide column meta">
        <h4>(ii)</h4>
      </div>
      <div class="one wide column" id="empty">
      </div>
      <div class="ten wide column content">
        <h5>Purposes</h5>
		<p>Similarly, the purposes or the category of purposes for which the Digital ID is used must always be backed by law and clearly and explicitly defined.<sup class="superscript"><a href="#fn29">29</a></sup><a name="ref29"></a> In a common law country, this can be done in the Statement of Objects and Reasons behind introducing the law, in the Notes and Clauses of the individual provisions of the law, or in the ministerial speech moving the law in legislature.</p>
		<p class="indent">The data collected by the State for the fulfilment of the legitimate State aim must be used to fulfil only those legitimate purposes that flow from the said aim, the burden of proving which is upon the State.<sup class="superscript"><a href="#fn30">30</a></sup><a name="ref30"></a> The nature of data required to fulfill this legitimate aim must also be expressly specified. The Digital ID should not be used for any extraneous or unauthorised purposes,<sup class="superscript"><a href="#fn31">31</a></sup><a name="ref31"></a> such as surveillance.</p>
		<p class="indent">A clearly defined purpose limitation<sup class="superscript"><a href="#fn32">32</a></sup><a name="ref32"></a> of the Digital ID will allows users to limit the collection and retention of personal data to what is ‘strictly necessary’ and exercise their rights to object to any processing that is not considered ‘strictly necessary.’&thinsp;<sup class="superscript"><a href="#fn33">33</a></sup><a name="ref33"></a> It will also prevent expansion of the project by way of mission creep.</p>
		<p class="indent">In the context of a Digital ID, for instance, if the aim of the ID is to authenticate users for the provision of services, the Legislature should consider whether it is necessary to collect the biometric information of an individual (or if demographic information would suffice), and if so, should this biometric information include fingerprints or DNA samples? The Digital ID law should also clarify whether the sensitive personal information collected for one purpose (e.g. for provision of benefits) can be used for an entirely <em>unrelated</em> purpose (e.g. SIM card authentication). Ideally, it should not, and any change of purpose/new purpose should be notified to the data subject for fresh consent.<sup class="superscript"><a href="#fn34">34</a></sup><a name="ref34"></a> Finally, a well defined purpose will enable citizens to determine whether centralised storage or long term retention of their data is necessary to achieve the purpose of the national Digital ID law.<sup class="superscript"><a href="#fn35">35</a></sup><a name="ref35"></a></p>
      </div>
      <div class="five wide column meta">
        <h3>1.4</h3>
      </div>
      <div class="one wide column" id="empty">
      </div>
      <div class="ten wide column content">
        <h6>Redressal Mechanism</h6>
        <h4>Does the law provide for adequate redressal mechanisms against actors who use the Digital ID and govern its use?</h4>
        <p>Adequate redressal mechanisms would necessarily include the following three requirements —</p>
      </div>
      <div class="five wide column meta">
        <h4>(i)</h4>
      </div>
      <div class="one wide column" id="empty">
      </div>
      <div class="ten wide column content">
        <h5>User Notification</h5>
		<p>Individuals must be notified or at least be able to access information on when their Digital ID is used in any way, e.g. during every authentication procedure. This will allow citizens to be informed of every instance of usage of their personal data, as is with the case of credit and debit cards.<sup class="superscript"><a href="#fn36">36</a></sup><a name="ref36"></a></p>
		<p class="indent">There should also be proactive notification when there is a breach of their data. A national ID system, by its very nature, will be collecting and storing large swathes of sensitive and personal demographic, and possibly biometric information of the country’s residents/citizens. The possibility of data breach thus, cannot be ruled out, and is especially dangerous when permanent identifiers like biometrics are used (which is another reason why biometrics should ideally not be a part of the Digital ID system). Hence, the Digital ID law should put in place legal requirements for the affected agency/data controller to notify the affected residents, as soon as a data breach occurs, and explain to them the impact of this breach.<sup class="superscript"><a href="#fn37">37</a></sup><a name="ref37"></a> This also ties in with the principle of accountability.</p>
      </div>
      <div class="five wide column meta">
        <h4>(ii)</h4>
      </div>
      <div class="one wide column" id="empty">
      </div>
      <div class="ten wide column content">
        <h5>Access and Correction</h5>
		<p>The rights to access and correction are derived from the citizens’ right to know, including their right to receive information, which are a part of the right to freedom of speech and expression.<sup class="superscript"><a href="#fn38">38</a></sup><a name="ref38"></a></p>
		<p class="indent">Individuals must have the right to access personally identifiable information collected through the use of Digital ID, to be able to confirm the data being held by the data controller, and to be able to obtain a copy of the same.<sup class="superscript"><a href="#fn39">39</a></sup><a name="ref39"></a> In the context of Digital IDs, this will enable the citizens to know the different agencies that have access to, and are able to process their digital ID information, including their biometric information. They should also have the ability to seek corrections, amendments, or deletion of such information where it is inaccurate.<sup class="superscript"><a href="#fn40">40</a></sup><a name="ref40"></a></p>
      </div>
      <div class="five wide column meta">
        <h4>(iii)</h4>
      </div>
      <div class="one wide column" id="empty">
      </div>
      <div class="ten wide column content">
        <h5>Due Process</h5>
		<p>A Digital ID law should have a well-designed grievance redress framework that addresses concerns of accountability, transparency, and user-friendliness.<sup class="superscript"><a href="#fn41">41</a></sup><a name="ref41"></a></p>
		<p class="indent">Individuals must be entitled to a fair and public hearing within a reasonable time by an independent, competent, and impartial judicial authority that is established by law, in cases where provisions of law governing the Digital ID are violated. This should take the form of adequate civil and criminal grievance redress mechanisms, with separate procedures for appeal.  Appropriate remedies for damage caused due to violations or errors must be accounted for, including in the form of monetary compensation where necessary.</p>
		<p class="indent">Civil redress mechanisms will have to be set up to deal with issues of omission or deactivation of the Digital ID (due to provision of false information or non-use), errors in the enrolment and verification process, or when there is an authentication failure (to prevent exclusion). All these acts have serious civil consequences of excluding citizens from the benefits of the Digital ID system, and thus, any adverse act (such as deactivating the ID, rejecting the enrolment, or denying benefits due to authentication failure) should be preceded by following due process and giving the aggrieved citizen a proper hearing.<sup class="superscript"><a href="#fn42">42</a></sup><a name="ref42"></a> It is also important that both civil and criminal redressal proceedings can be initiated by both regulators responsible for governance of Digital ID, as well as individuals — or class of individuals — who may be impacted.<sup class="superscript"><a href="#fn43">43</a></sup><a name="ref43"></a></p>
      </div>
      <div class="five wide column meta">
        <h3>1.5</h3>
      </div>
      <div class="one wide column" id="empty">
      </div>
      <div class="ten wide column content">
        <h6>Accountability</h6>
		<h4>Are there adequate systems for accountability of governing bodies, users of Digital ID and other actors?</h4>
        <p>The collection, storage, and use of sensitive and personal information occasions a duty of care for its protection.<sup class="superscript"><a href="#fn44">44</a></sup><a name="ref44"></a> The laws governing Digital ID must provide for systems of accountability for the bodies that implement and operate the Digital ID, regulators, public and private actors which use Digital ID in any way, and other enabling or supporting actors.</p>
		<p class="indent">The principle of accountability is a well-recognised privacy principle.<sup class="superscript"><a href="#fn45">45</a></sup><a name="ref45"></a> However, it is important to understand that accountability does not replace existing law, nor does it redefine privacy. Instead, it merely seeks to improve <em>privacy governance</em> and ensure effective compliance with existing laws to achieve the law’s privacy objectives.<sup class="superscript"><a href="#fn46">46</a></sup><a name="ref46"></a> Given the vast enterprise of data collection, storage, and use that is carried out by the government and possibly private actors, individuals often have little knowledge or control over their personal data. Accountability thus assumes an even greater role in this context.</p>
		<p class="indent">Accountability can be both <em>ex-ante</em> and <em>ex-post</em>,<sup class="superscript"><a href="#fn47">47</a></sup><a name="ref47"></a> and achieved through a variety of ways — better enforcement of laws, an effective regulatory framework, a proper delineation of responsibility amongst the various actors in the Digital ID system, transparency, user breach notification, and efficient grievance redress procedures.</p>
		<p class="indent">In a Digital ID system, it can also take the form of requiring the Digital ID agency to maintain an access log (tracking who accessed the data, when, where, and for what purpose) that is associated with the identity for the user to consult at any time.<sup class="superscript"><a href="#fn48">48</a></sup><a name="ref48"></a> This will help prevent any misuse. If such logs are maintained, unauthorized access must be especially guarded against, as the logs, together with the metadata they generate, enable major inferences to be made about an individual. To that end, there must be a process to periodically delete or anonymise older logs. A legislation governing Digital ID should ideally also separate the role of the administrator, who is in charge of the storage of personal data and regulator, who licenses other agencies to perform enrolment and authentication functions and is in charge of grievance redress of the Digital ID program. There is an inherent conflict of interest if the same body performs both roles.<sup class="superscript"><a href="#fn49">49</a></sup><a name="ref49"></a> Thus, the Digital ID law should set up an <em>independent</em> and robust regulatory or monitoring framework, so that the administrator of the Digital ID can be held responsible for any breach in the database.</p>
      </div>
      <div class="five wide column meta">
        <h3>1.6</h3>
      </div>
      <div class="one wide column" id="empty">
      </div>
      <div class="ten wide column content">
        <h6>Mission Creep</h6>
		<h4>Is there a legislative and judicial oversight mechanism to deal with cases of mission creep in the use of Digital ID?</h4>
		<p>Mission creep or function creep is the idea that a system or technology that has been developed for one purpose, or with one set of capabilities, ends up getting used for other purposes it was not originally intended for. These subsequent uses may be advantageous, but more often than not, are pernicious, and include profiling and surveillance.<sup class="superscript"><a href="#fn50">50</a></sup><a name="ref50"></a> Mission creep or function creep thus, ends up conflicting with the right to privacy.</p>
		<p class="indent">Mission creep takes place on the back of data collected/generated through the use of a Digital ID. It is particularly problematic when the Digital ID captures biometric information, stores it centrally, and then uses it across different services (e.g. identification for a drivers’ license to authentication for receipt of benefits), since the mission creep raises heightened concerns of surveillance.<sup class="superscript"><a href="#fn51">51</a></sup><a name="ref51"></a></p>
		<p class="indent">As time progresses, Digital ID systems have a greater probability of suffering from mission creep. To prevent mission creep, the governing Act must explicitly specify the proposed uses of the Digital ID and the particular data being collected. Further, it is important to explain to the citizens the nature of their personal information being collected, the purpose it will be used for, and the agency using it. This is also in line with the traditional notice and consent framework and the idea of informational self-determination. Thereafter, the executive authority must not be able to allow for attempts to use the Digital ID for newer purposes unless there is a proper legislative process for deliberating the additional uses, or a judicial examination of these uses against the legitimate aims, or a fresh consent sought from the citizens.</p>
		<p class="indent">Some of the recognised mechanisms to limit mission creep are<sup class="superscript"><a href="#fn52">52</a></sup><a name="ref52"></a> —</p>
		<p style="padding: 1em; font-style: italic;">“(i) limiting the amount of data that is collected for any stated purpose; (ii) enabling regulation to limit technological access to the system; (iii) concerted debates with all stakeholders and public participation; (iv) dispersion of multiple enablers for a system; and (v) enabling choices for user participation.”</p>
		<p>The above strategies if specifically included in the law governing Digital ID, can help ensure that sensitive and personal information collected for one purpose does not end up getting used for another, unintended purpose. This will aid in constraining government power.</p>
      </div>
      <div class="sixteen wide column break">
      </div>
      <div class="five wide column meta">
        <h3>Rights based Tests</h3>
      </div>
      <div class="one wide column" id="empty">
      </div>
      <div class="ten wide column content">
		<p>The most clear and outright critiques of Digital ID systems have come in light of their violations of the right to privacy. Across jurisdictions, critics have discussed different forms of violations of privacy, including mandatory collection of sensitive personal data such as biometrics, lack of robust access-control mechanisms, inadequate protection of private sector collection of data, and increased behavioral profiling through use of one identifier for all services. Alongside, there have also been serious questions raised about exclusion concerns where absence of an ID or failures in its functioning can lead to denial of basic entitlements and benefits. Key rights-based principles are highlighted below —</p>
      </div>
      <div class="five wide column meta">
        <h3>2.1</h3>
      </div>
      <div class="one wide column" id="empty">
      </div>
      <div class="ten wide column content">
        <h6>Necessary and Proportionate</h6>
		<h4>Are the privacy violations arising from the use of Digital ID necessary and proportionate to achieve the legitimate aim?</h4>
        <p>The Hudumba Bill has limited provisions on redressal mechanisms to deal with violation of rights. It only has an enabling provision under which complaint procedure would be created, but such mechanisms are not defined in the legislation itself.<a href="#fn9" class="superscript">9</a><a name="ref9"></a></p>
		<p class="pullquote">The redressal mechanisms under the proposed Huduma Bill are extremely inadequate. </p>
		<p>The Data Protection Act has certain redressal measures for violations: Section 56 allows aggrieved data subjects to lodge a complaint with the Data Commissioner, who has the powers to investigate the offence,<a href="#fn10" class="superscript">10</a><a name="ref10"></a> and enforce penalties.<a href="#fn11" class="superscript">11</a><a name="ref11"></a> Appeals from the Data Commissioner's action can be brought to the High Court of Kenya.<a href="#fn12" class="superscript">12</a><a name="ref12"></a> Data subjects are also entitled to compensation for damage caused by actions of data controller or processor.<a href="#fn13" class="superscript">13</a><a name="ref13"></a></p>
      </div>
      <div class="five wide column meta">
        <h3>1.9</h3>
      </div>
      <div class="one wide column" id="empty">
      </div>
      <div class="ten wide column content">
        <h5>Accountability</h5>
		<h4>Is there an independent and adequate regulatory mechanism to ensure accountability of the administrator of the digital ID?</h4>
		<p>The NIIMS system is intended to be governed by NIIMS Coordination Committee led by the Principal Secretary to the Home Department in Kenya.</p>
		<p class="pullquote">The proposed Huduma Bill does not envisage an independent regulator.</p>
        <p>The administrators are not made responsible for any breach of the system. In fact there are no provisions in the Bill to ensure accountability from the NIIMS Coordination Committee. The Principal Secretary is authorized to establish mechanisms for lodging complaints and facilitating amicable and expeditious settlement of disputes by any person aggrieved by any decision under the Bill.<a href="#fn14" class="superscript">14</a><a name="ref14"></a> This poses a conflict of interest as adjudicatory powers are being delegated or discharged by bodies which may be subject to the same adjudication.</p>
      </div>
      <div class="five wide column meta">
        <h3>1.10</h3>
      </div>
      <div class="one wide column" id="empty">
      </div>
      <div class="ten wide column content">
        <h5>Mission Creep</h5>
		<h4>Does the governing law explicitly specify the proposed purposes of the digital ID?</h4>
		<p class="pullquote">The purposes for which Huduma Namba may be used are not clearly specified in the proposed Huduma Bill.</p>
		<p>It is also not made clear which are the categories of actors who may make use of it. However, the Bill does provide a list of mandatory uses of Huduma Namba<a href="#fn15" class="superscript">15</a><a name="ref15"></a> which are indicative, but is silent on other voluntary uses. </p>
		<p class="indent">However, the Kenyan High Court in the <em>Huduma Judgment</em> held that purpose limitation was in built in the legal design of NIIMS and that the purposes are identification and verification. This does not serve as effective purpose limitation as identification and verification are features of the ID system itself and would be part of <em>any</em> use of the ID. Without codifying specific instances or uses for which the ID system may be leveraged, the governing law has failed the purpose test. </p>
      </div>
      <div class="five wide column meta">
        <h3>1.11</h3>
      </div>
      <div class="one wide column" id="empty">
      </div>
      <div class="ten wide column content">
        <h5>Newer Purposes</h5>
		<h4>In case there are newer purposes identified, are there regulatory procedures in place to determine their legitimacy?</h4>
		<p class="pullquote">There are no provisions in place or practices envisaged to have a process for determining the appropriateness or legitimacy of new uses and purposes.</p>
		<p>Even for mandatory uses, the provisions of Huduma Bill state that any other purposes for public service may be specified but this is not made clear. It is unclear how this will be impacted by the Huduma Judgment which clearly identifies identification and verification and purposes of the NIIMS. Additionally, the Huduma Bill clearly states that upon setting up of the NIIMS database, every government agency shall authenticate foundational data they hold of an individual with the NIIMS database.<a href="#fn16" class="superscript">16</a><a name="ref16"></a> It also states that every government agency delivering a public service shall be linked to the NIIMS database in such manner as to enable such agency to — (a) authenticate personal data in their possession with NIIMS; and (b) transmit, access or retrieve information necessary for the proper discharge of agency’s functions. This suggests an expanded scope of an unspecified number of actors using the personal data being collected.</p>
      </div>
      <div class="sixteen wide column break">
      </div>
      <div class="six wide column" id="empty">
      </div>
      <div class="ten wide column title">
        <h3>Rights based Tests</h3>
      </div>
      <div class="five wide column meta">
        <h3>2.1</h3>
      </div>
      <div class="one wide column" id="empty">
      </div>
      <div class="ten wide column content">
        <h5>Data Minimisation</h5>
		<h4>Are principles of data minimisation followed in the collection, use, and retention of personal data?</h4>
		<p>The Registration of Persons Act does not address data minimisation concerns.</p>
		<p class="pullquote">The principles of data minimisation are also not discussed or clearly reflected in the proposed Huduma Bill.</p>
		<p>The Bill envisages centralised collection of unspecified functional data.<a href="#fn17" class="superscript">17</a><a name="ref17"></a> However it does not provide any principles on how the collection, use and retention of such data can be minimised. The Bill does refer to principles of purpose limitation in that the purposes for which data is collected will be specified to individuals, and that the individual consent shall be sought for further sharing of data with third parties.<a href="#fn18" class="superscript">18</a><a name="ref18"></a></p>
      </div>
      <div class="five wide column meta">
        <h3>2.2</h3>
      </div>
      <div class="one wide column" id="empty">
      </div>
      <div class="ten wide column content">
        <h5>Access to Data</h5>
		<h4>Does the law specify access that various private and public actors have to personal data?</h4>
		<p>Currently there are no laws that govern access of private and public actors.</p>
		<p class="pullquote">The proposed Huduma Bill provides an expansive list of mandatory uses, which gives an indication of public bodies which may use it.<a href="#fn19" class="superscript">19</a><a name="ref19"></a></p>
		<p>It is not clear whether the agencies in charge of these functions may get access to any information collected. The Huduma Bill is silent on the access or use that private parties may have to the data collected.</p>
		<p class="indent">It was argued in the Huduma Namba case that the NIIMS’ legal framework was open-ended and did not specify the uses that it would be put to. On this question, however the court said that purpose limitation was a part of the legal framework and that the purpose of data collection was identification and verification of individuals. It is not clear whether this means that the data collected can only be used for the purpose of verification.</p>
      </div>
      <div class="five wide column meta">
        <h3>2.3</h3>
      </div>
      <div class="one wide column" id="empty">
      </div>
      <div class="ten wide column content">
        <h5>Exclusions due to Design Flaws</h5>
		<h4>Is the use of digital ID to access services exclusionary?</h4>
		<p class="pullquote">The Registration of Persons Act does not have any clear provisions on exclusionary impact and how to address it.</p>
        <p>The Huduma Bill authorizes the development of measures to mitigate on any legal, procedural and social barriers that may limit enrolment, with special attention being paid to any group or persons at risk of exclusion. However, despite the provisions in Section 60, the Bill does not sufficiently address the challenges faced by marginalised communities such as Somalis and Nubians as well as Kenyan women, during the registration of persons.</p>
		<p class="indent">This is one of the main arguments made by the petitioners in the lawsuit currently pending against the NIIMS system. However, in the Huduma Judgment, the Kenyan High Court did not provide a finding on the question whether making enrolment into NIIMS mandatory in order to access entitlements or services would be unlawful. Currently there are no clear provisions that mandate the use of the <em>Huduma Namba</em> to access services and entitlements and therefore, the Kenyan High court may not have felt the need to rule conclusively on this point yet.</p>
      </div>
      <div class="five wide column meta">
        <h3>2.4</h3>
      </div>
      <div class="one wide column" id="empty">
      </div>
      <div class="ten wide column content">
        <h5>Exclusions due to Failure</h5>
		<h4>Does failure of the ID system lead to exclusion?</h4>
		<p>In our desk research we did not come across clear account of exclusions arising as a result of the use of the digital identity. However, according to the Kenya National Electrification Strategy, the country will be fully electrified by 2022. It is also estimated that about 90% of the population of Kenya live within range of a mobile tower.<a href="#fn20" class="superscript">20</a><a name="ref20"></a> These factors do mean that those without electricity and mobile connectivity will suffer exclusionary effects of digital identity.</p>
		<p class="pullquote">The lack of clear alternatives to the Huduma Namba scheme suggests that exclusion will remain a concern. </p>
		<p>Additionally, there are no clear provisions addressing exclusions arising out of incorrect data collection in the Bill.</p>
      </div>
      <div class="sixteen wide column break">
      </div>
      <div class="six wide column" id="empty">
      </div>
      <div class="ten wide column title">
        <h3>Risk based Tests</h3>
      </div>
      <div class="five wide column meta">
        <h3>3.1</h3>
      </div>
      <div class="one wide column" id="empty">
      </div>
      <div class="ten wide column content">
        <h5>Risk Assessment</h5>
		<h4>Is the ID system regulated taking into account its potential risks?</h4>
		<p class="pullquote">There is no clear consideration of risk based factors in the proposed Huduma Bill.</p>
		<p>While Section 60 of the Bill seeks to address exclusionary risks of Huduma Namba and states that the Cabinet Secretary shall develop measures to mitigate on any legal, procedural, and social barriers that may limit the enrolment, with special attention being paid to any group of persons at risk of exclusion for cultural, political or other reasons, at the moment there is no clarity on what these measures could be.</p>
      </div>
      <div class="five wide column meta">
        <h3>3.2</h3>
      </div>
      <div class="one wide column" id="empty">
      </div>
      <div class="ten wide column content">
        <h5>Privacy Risk Mitigation</h5>
		<h4>Is there a national data protection law in place?</h4>
		<p>During the pendency of the Huduma Namba case, the Kenyan parliament passed the Data Protection Act. The Kenyan High Court noted that the provisions of this law were in line with internationally recognised best practices, however without the implementation of the provisions of the legislation, the Huduma Namba project should not move forward. For this, a Data Protection Authority needs to be established under the Data Protection Act. </p>
		<p class="pullquote">As the Kenyan High Court itself noted in the <em>Huduma Judgment</em>, currently the national data protection law has not been implemented in Kenya.</p>
      </div>
      <div class="five wide column meta">
        <h3>3.3</h3>
      </div>
      <div class="one wide column" id="empty">
      </div>
      <div class="ten wide column content">
        <h5>Privacy by Design</h5>
		<h4>Are there privacy by design systems that minimise the harms from data breach?</h4>
		<p>There are no clearly identified privacy by design strategies to minimise the harms of data breach.</p>
      </div>
      <div class="five wide column meta">
        <h3>3.4</h3>
      </div>
      <div class="one wide column" id="empty">
      </div>
      <div class="ten wide column content">
        <h5>Response to Risks</h5>
		<h4>Is there a mitigation strategy in place in case of failure or breach of the ID system?</h4>
		<p>The legislative framework does not envisage any clear mitigation strategies in case of failure or breach of the ID system.</p>
      </div>
      <div class="sixteen wide column break">
      </div>
      <div class="six wide column" id="empty">
      </div>
      <div class="ten wide column content">
        <h3>Notes</h3>
        <table class="footnote">
  		  <tr>
            <td class="number">1</td>
    		<td class="reference"><a name="fn1"></a>This is the legality prong of the proportionality tests used in most common law jurisdictions.&nbsp;&nbsp;<span class="internal-nav"><a href="#ref1">&uarr;</a></span></td>
  		  </tr>
  		  <tr>
    		<td class="number">2</td>
    		<td class="reference"><a name="fn2"></a><em>US v.  Jones</em>, 132 S. Ct. 945, 956 (2012) (Sotomayor, J., concurring) noting that <em>“Awareness that the Government may be watching chills associational and expressive freedoms.”</em>; Niva Elkin-Koren, Michal S. Gal, “The Chilling Effect of Governance-by-Data on Data Markets”, 86 <em>University of Chicago Law Review</em> (2019): 403.&nbsp;&nbsp;<span class="internal-nav"><a href="#ref2">&uarr;</em></a></span></td>
  		  </tr>
  		  <tr>
    		<td class="number">3</td>
    		<td class="reference"><a name="fn3"></a><em>State of Madhya Pradesh v. Thakur Bharat Singh</em>, 2 SCR 454 (1967).&nbsp;&nbsp;<span class="internal-nav"><a href="#ref3">&uarr;</em></a></span></td>
  		  </tr>
  		  <tr>
    		<td class="number">4</td>
    		<td class="reference"><a name="fn4"></a><em>Kharak Singh v. State of U.P.</em>, 1 SCR 332 (1964); <em>Bijoe Emmanuel v. State of Kerala</em>, 3 SCC 615 (1986), at paras 16, 19.&nbsp;&nbsp;<span class="internal-nav"><a href="#ref4">&uarr;</em></a></span></td>
  		  </tr>
  		  <tr>
    		<td class="number">5</td>
    		<td class="reference"><a name="fn5"></a><em>K.S. Puttaswamy v. Union of India</em>, 10 SCC 1 (2017), paras 310, 325 (Chandrachud J.), 638 (Kaul J.) [<em>“Puttaswamy”</em>]; <em>K.S. Puttaswamy v Union of India (II)</em>, 1 SCC 1 (2019), at paras 147, 557 [<em>“Aadhaar Judgment”</em>].&nbsp;&nbsp;<span class="internal-nav"><a href="#ref5">&uarr;</em></a></span></td>
  		  </tr>
  		  <tr>
    		<td class="number">6</td>
    		<td class="reference"><a name="fn6"></a><em>Provincial Picture Houses v. Wednesbury Corporation</em>, (1947) 1 KB 223.&nbsp;&nbsp;<span class="internal-nav"><a href="#ref6">&uarr;</em></a></span></td>
  		  </tr>
  		  <tr>
    		<td class="number">7</td>
    		<td class="reference"><a name="fn7"></a><em>R v. Big M Drug Mart Ltd.</em>, (1985) 1 SCR 295.&nbsp;&nbsp;<span class="internal-nav"><a href="#ref7">&uarr;</em></a></span></td>
  		  </tr>
  		  <tr>
    		<td class="number">8</td>
    		<td class="reference"><a name="fn8"></a><em>S v. Makwanyane</em>, (1995) 3 SA 391 (CC).&nbsp;&nbsp;<span class="internal-nav"><a href="#ref8">&uarr;</em></a></span></td>
  		  </tr>
  		  <tr>
    		<td class="number">9</td>
    		<td class="reference"><a name="fn9"></a><em>Belvedere Alberghiera v. Italy</em>, 31524/96, (2000), at 56-58.&nbsp;&nbsp;<span class="internal-nav"><a href="#ref9">&uarr;</em></a></span></td>
  		  </tr>
  		  <tr>
    		<td class="number">10</td>
    		<td class="reference"><a name="fn10"></a><em>Uzun v. Germany</em>, 53 EHRR 852 (2010), para 60; Perry v. UK, 39 EHRR 3, (2004) para 45.&nbsp;&nbsp;<span class="internal-nav"><a href="#ref10">&uarr;</em></a></span></td>
  		  </tr>
  		  <tr>
    		<td class="number">11</td>
    		<td class="reference"><a name="fn11"></a><em>Malone v. UK</em>, ECHR 10, (1984) at para 67.&nbsp;&nbsp;<span class="internal-nav"><a href="#ref11">&uarr;</em></a></span></td>
  		  </tr>
  		  <tr>
    		<td class="number">12</td>
    		<td class="reference"><a name="fn12"></a><em>Slivenko v. Latvia</em>, 48321/99 (2003).&nbsp;&nbsp;<span class="internal-nav"><a href="#ref12">&uarr;</a></span></td></td>
  		  </tr>
  		  <tr>
    		<td class="number">13</td>
    		<td class="reference"><a name="fn13"></a><em>Malone v. UK</em>, ECHR 10, (1984).&nbsp;&nbsp;<span class="internal-nav"><a href="#ref13">&uarr;</a></span></td></td>
  		  </tr>
  		  <tr>
    		<td class="number">14</td>
    		<td class="reference"><a name="fn14"></a><em>Vukota-Bojić v. Switzerland</em>, ECHR 899, (2016) at paras 73, 77; <em>Piechowicz v. Poland</em>, ECHR 689,(2012) at para 212.&nbsp;&nbsp;<span class="internal-nav"><a href="#ref14">&uarr;</a></span></td></td>
  		  </tr>
  		  <tr>
    		<td class="number">15</td>
    		<td class="reference"><a name="fn15"></a>Victoria Aitken, “An Exposition Of Legislative Quality And Its Relevance For Effective Development,” 2 <em>PROLAW Student Journal</em>, 1-43 (2013); Helen Xanthaki, <em>Drafting Legislation: Art and Technology of Rules for Regulation</em> (Hart Publishing, 2014); Vrinda Bhandari and Renuka Sane, “A Critique of the Aadhaar Legal Framework,” 31(1) NLSIR 1 (2019) (forthcoming).&nbsp;&nbsp;<span class="internal-nav"><a href="#ref15">&uarr;</em></a></span></td>
  		  </tr>
  		  <tr>
    		<td class="number">16</td>
    		<td class="reference"><a name="fn16"></a>Timothy Endicott, <em>Vagueness in Law</em> (OUP, 2000).&nbsp;&nbsp;<span class="internal-nav"><a href="#ref16">&uarr;</em></a></span></td>
  		  </tr>
  		  <tr>
    		<td class="number">17</td>
    		<td class="reference"><a name="fn17"></a><em>Grayned v. City of Rockford</em>, 408 U.S. 104, 108 (1972); <em>A.N. Parasuraman v. State of Tamil Nadu</em>, 4 SCC 683 (1989).&nbsp;&nbsp;<span class="internal-nav"><a href="#ref17">&uarr;</em></a></span></td>
  		  </tr>
  		  <tr>
    		<td class="number">18</td>
    		<td class="reference"><a name="fn18"></a><em>Peruzzo & Martens v. Germany</em>, ECHR 743, (2013), para 34.&nbsp;&nbsp;<span class="internal-nav"><a href="#ref18">&uarr;</em></a></span></td>
  		  </tr>
  		  <tr>
    		<td class="number">19</td>
    		<td class="reference"><a name="fn19"></a><em>S & Marper v. UK</em>, ECHR 1581, (2008), para 101.&nbsp;&nbsp;<span class="internal-nav"><a href="#ref19">&uarr;</em></a></span></td>
  		  </tr>
  		  <tr>
    		<td class="number">20</td>
    		<td class="reference"><a name="fn20"></a>For an analysis of ECtHR’s jurisprudence on this point, see, Steven Greer, “The exceptions to Articles 8 to 11 of the European Convention on Human Rights”, Human Rights File No. 15, Council of Europe (1997), <a href="https://www.echr.coe.int/LibraryDocs/DG2/HRFILES/DG2-EN-HRFILES-15(1997).pdf" target="_blank"><em>https://www.echr.coe.int/LibraryDocs/DG2/HRFILES/DG2-EN-HRFILES-15(1997).pdf</em></a>, at 14.&nbsp;&nbsp;<span class="internal-nav"><a href="#ref20">&uarr;</em></a></span></td>
  		  </tr>
  		  <tr>
    		<td class="number">21</td>
    		<td class="reference"><a name="fn21"></a>Article 8(2), European Convention of Human Rights, 1950; <em>Puttaswamy</em>, supra, paras 311-312.&nbsp;&nbsp;<span class="internal-nav"><a href="#ref21">&uarr;</em></a></span></td>
  		  </tr>
  		  <tr>
    		<td class="number">22</td>
    		<td class="reference"><a name="fn22"></a><em>Mozer v. the Republic of Moldova and Russia</em>, No. 11138/2010, (Grand Chamber) (2016), para 194.&nbsp;&nbsp;<span class="internal-nav"><a href="#ref22">&uarr;</em></a></span></td>
  		  </tr>
  		  <tr>
    		<td class="number">23</td>
    		<td class="reference"><a name="fn23"></a>Principle 2, Necessity and Proportionality Principles, International Principles on the Application of Human Rights to Communication Surveillance (May, 2014) available at <a href="https://necessaryandproportionate.org/principles#principle2" target="_blank"><em>https://necessaryandproportionate.org/principles#principle2</em></a>.&nbsp;&nbsp;<span class="internal-nav"><a href="#ref23">&uarr;</em></a></span></td>
  		  </tr>
  		  <tr>
    		<td class="number">24</td>
    		<td class="reference"><a name="fn24"></a>Daniel Solove, “10 Reasons Why Privacy Matters”, <em>TeachPrivacy (blog)</em>, January 20 2014, <a href="https://teachprivacy.com/10-reasons-privacy-matters/" target="_blank"><em>https://teachprivacy.com/10-reasons-privacy-matters/</em></a>.&nbsp;&nbsp;<span class="internal-nav"><a href="#ref24">&uarr;</em></a></span></td>
  		  </tr>
  		  <tr>
    		<td class="number">25</td>
    		<td class="reference"><a name="fn25"></a>1 SCC 1 (2019).&nbsp;&nbsp;<span class="internal-nav"><a href="#ref25">&uarr;</em></a></span></td>
  		  </tr>
  		  <tr>
    		<td class="number">26</td>
    		<td class="reference"><a name="fn26"></a><em>Aadhaar Judgment, supra</em>, para (447)(4)(h). For a further analysis on the Court’s reasons for striking down Section 57 of the Aadhaar Act, see Vrinda Bhandari and Rahul Narayan, “In striking down Section 57, SC has curtailed the function creep and financial future of Aadhaar,” <em>The Wire</em>, Sept. 28, 2018, <a href="https://thewire.in/law/in-striking-down-section-57-sc-has-curtailed-the-function-creep-and-financial-future-of-aadhaar" target="_blank"><em>https://thewire.in/law/in-striking-down-section-57-sc-has-curtailed-the-function-creep-and-financial-future-of-aadhaar</em></a>. &nbsp;&nbsp;<span class="internal-nav"><a href="#ref26">&uarr;</em></a></span></td>
  		  </tr>
  		  <tr>
    		<td class="number">27</td>
    		<td class="reference"><a name="fn27"></a>Through an amendment and ordinance, the government has now sought to (re-)introduce voluntary private sector involvement in the Aadhaar and Other Laws (Amendment) Bill, 2019, with diverging views on whether this is legal and/or appropriate. For arguments on why the Amendment is contrary to the Judgment of the Supreme Court see Raghu, “Six Reasons Why the Aadhaar Amendment Ordinance Undermines Democracy,” <em>The Wire</em>, Mar. 12, 2019, <a href="https://thewire.in/government/aadhaar-amendments-ordinance-democracy" target="_blank"><em>https://thewire.in/government/aadhaar-amendments-ordinance-democracy</em></a>; Vrinda Bhandari, “Why Amend the Aadhaar Act Without First Passing a Data Protection Bill?”, <em>The Wire</em>, Jan. 4, 2019, <a href="https://thewire.in/law/aadhaar-act-amendment-data-protection" target="_blank"><em>https://thewire.in/law/aadhaar-act-amendment-data-protection</em></a>. For (opposing) arguments endorsing the government’s amendment, see Rahul Matthan, “The Aadhaar Amendment and Private Sector Access”, <em>LiveMint</em>, 08 Jan 2019, <a href="https://www.livemint.com/Opinion/jmxPkXXGWeEfiAsCsA1xnO/Opinion--The-Aadhaar-amendment-and-private-sector-access.html" target="_blank"><em>https://www.livemint.com/Opinion/jmxPkXXGWeEfiAsCsA1xnO/Opinion--The-Aadhaar-amendment-and-private-sector-access.html</em></a>; Nehaa Chaudhari, “Supreme Court has banned private companies from using Aadhaar. What does it actually mean?”, <em>Scroll.in</em>, October 4 2018, <a href="https://scroll.in/article/896771/supreme-court-has-banned-private-companies-from-using-aadhaar-what-does-it-actually-mean." target="_blank"><em>https://scroll.in/article/896771/supreme-court-has-banned-private-companies-from-using-aadhaar-what-does-it-actually-mean.</em></a>&nbsp;&nbsp;<span class="internal-nav"><a href="#ref27">&uarr;</em></a></span></td>
			  </tr>
  			  <tr>
    			<td class="number">28</td>
    			<td class="reference"><a name="fn28"></a>“State Laws Restricting Private Use of Social Security Numbers.” Advocacy. Accessed August 21, 2019. <a href="https://advocacy.consumerreports.org/press_release/state-laws-restricting-private-use-of-social-security-numbers/" target="_blank"><em>https://advocacy.consumerreports.org/press_release/state-laws-restricting-private-use-of-social-security-numbers/</em></a>.&nbsp;&nbsp;<span class="internal-nav"><a href="#ref28">&uarr;</em></a></span></td>
			  </tr>
			  <tr>
    			<td class="number">29</td>
    			<td class="reference"><a name="fn29"></a>Access Now, “National Digital Identity Programmes: What’s Next?”, March 2018, 22 <a href="https://www.accessnow.org/cms/assets/uploads/2018/03/Digital-Identity-Paper-digital-version-Mar20.pdf" target="_blank"><em>https://www.accessnow.org/cms/assets/uploads/2018/03/Digital-Identity-Paper-digital-version-Mar20.pdf</em></a>. [“AccessNow”]&nbsp;&nbsp;<span class="internal-nav"><a href="#ref29">&uarr;</em></a></span></td>
			  </tr>
			  <tr>
    			<td class="number">30</td>
    			<td class="reference"><a name="fn30"></a>Principles 3 and 5, Necessity and Proportionality Principles, <em>International Principles on the Application of Human Rights to Communication Surveillance</em> (May, 2014), <a href="https://necessaryandproportionate.org/principles#principle3" target="_blank"><em>https://necessaryandproportionate.org/principles#principle3</em></a>. &nbsp;&nbsp;<span class="internal-nav"><a href="#ref30">&uarr;</em></a></span></td>
			  </tr>
  			  <tr>
    			<td class="number">31</td>
    			<td class="reference"><a name="fn31"></a><em>Puttaswamy, supra</em>, para 311.&nbsp;&nbsp;<span class="internal-nav"><a href="#ref31">&uarr;</em></a></span></td>
			  </tr>
  			  <tr>
    			<td class="number">32</td>
    			<td class="reference"><a name="fn32"></a><em>Puttaswamy, supra</em>.&nbsp;&nbsp;<span class="internal-nav"><a href="#ref32">&uarr;</em></a></span></td>
			  </tr>
  			  <tr>
    			<td class="number">33</td>
    			<td class="reference"><a name="fn33"></a>AccessNow, <em>supra</em>, 23, 25.&nbsp;&nbsp;<span class="internal-nav"><a href="#ref33">&uarr;</em></a></span></td>
			  </tr>
  			  <tr>
                <td class="number">34</td>
    			<td class="reference"><a name="fn34"></a>For instance, Section 15 of the Indian Census Act, the records of the census are not admissible as evidence in any civil or criminal proceedings. See also the ‘Purpose Specification’ Principle and the ‘Use Limitation’ Principle in the OECD Privacy Framework, <a href="http://www.oecd.org/sti/ieconomy/oecd_privacy_framework.pdf" target="_blank"><em>http://www.oecd.org/sti/ieconomy/oecd_privacy_framework.pdf</em></a>, at 14.&nbsp;&nbsp;<span class="internal-nav"><a href="#ref34">&uarr;</em></a></span></td>
			  </tr>
  			  <tr>
    			<td class="number">35</td>
    			<td class="reference"><a name="fn35"></a><em>S & Marper, supra</em>, para 103.&nbsp;&nbsp;<span class="internal-nav"><a href="#ref35">&uarr;</em></a></span></td>
			  </tr>
  			  <tr>
    			<td class="number">36</td>
    			<td class="reference"><a name="fn36"></a>Nikhil Pahwa, “Learning from Aadhaar: 10 rules from nations on how not to make a mess of their digital IDs,” <em>Scroll.in</em>, <a href="https://scroll.in/article/858767/learning-from-aadhaar-10-rules-for-nations-on-how-not-to-make-a-mess-of-their-national-ids" target="_blank"><em>https://scroll.in/article/858767/learning-from-aadhaar-10-rules-for-nations-on-how-not-to-make-a-mess-of-their-national-ids</em></a> [“Nikhil Pahwa”].&nbsp;&nbsp;<span class="internal-nav"><a href="#ref36">&uarr;</em></a></span></td>
			  </tr>
  			  <tr>
    			<td class="number">37</td>
    			<td class="reference"><a name="fn37"></a>Report of the Group of Experts on Privacy, Government of India Planning Commission (October 16, 2012), <a href="https://www.dsci.in/content/report-group-experts-privacyconstituted-planning-commission-india" target="_blank"><em>https://www.dsci.in/content/report-group-experts-privacyconstituted-planning-commission-india</em></a>, [“Justice AP Shah Report”] 22, 70; AccessNow, <em>supra</em>, 29.&nbsp;&nbsp;<span class="internal-nav"><a href="#ref37">&uarr;</em></a></span></td>
			  </tr>
  			  <tr>
                <td class="number">38</td>
    			<td class="reference"><a name="fn38"></a><em>Indian Soaps & Toiletries Makers Association v. Ozair Hussain</em>, 3 SCC 641, (2013), at paras 28 and 29; <em>Reliance Petrochemicals v Indian Express</em>, 4 SCC 592, (1988) para 34.&nbsp;&nbsp;<span class="internal-nav"><a href="#ref38">&uarr;</em></a></span></td>
			  </tr>
  			  <tr>
    			<td class="number">39</td>
    			<td class="reference"><a name="fn39"></a>Justice AP Shah Report, <em>supra</em>, 25.&nbsp;&nbsp;<span class="internal-nav"><a href="#ref39">&uarr;</em></a></span></td>
			  </tr>
  			  <tr>
    			<td class="number">40</td>
    			<td class="reference"><a name="fn40"></a>See in the context of general data protection legislation, Sections 45 (right of access) and 46 (right of rectification) of the UK Data Protection Act, 1998.&nbsp;&nbsp;<span class="internal-nav"><a href="#ref40">&uarr;</em></a></span></td>
			  </tr>
  			  <tr>
    			<td class="number">41</td>
    			<td class="reference"><a name="fn41"></a>For elements of a well-designed grievance redress framework, see Vrinda Bhandari and Renuka Sane, <em>Critique of the Aadhaar Legal Framework, supra</em>, 18-20.&nbsp;&nbsp;<span class="internal-nav"><a href="#ref41">&uarr;</em></a></span></td>
			  </tr>
  			  <tr>
    			<td class="number">42</td>
    			<td class="reference"><a name="fn42"></a><em>Sahara India v CIT</em>, 14 SCC 151, (2008) para 29.&nbsp;&nbsp;<span class="internal-nav"><a href="#ref42">&uarr;</em></a></span></td>
			  </tr>
  			  <tr>
    			<td class="number">43</td>
    			<td class="reference"><a name="fn43"></a>The Indian Aadhaar experience is instructive to understand the issues with criminal redress. Despite designating various actions as specific criminal offences, section 47 of the Aadhaar Act permitted only the UIDAI to initiate criminal prosecution, thereby eliminating the involvement of the Aadhaar number holder entirely. The constitutionality of this provision was challenged before the Supreme Court, which held <em>“Insofar as Section 47 of the Act which provides for the cognizance of offence only on a complaint made by the Authority or any officer or person authorised by it is concerned, it needs a suitable amendment to include the provision for filing of such a complaint by an individual/victim as well whose right is violated.”</em> Subsequently, the government added a proviso to Section 47 through the Aadhaar Amendment Act, 2019, allowing the Aadhaar number holder or individual to file a criminal complaint for the commission of certain specified offences.&nbsp;&nbsp;<span class="internal-nav"><a href="#ref43">&uarr;</em></a></span></td>
			  </tr>
  			  <tr>
    			<td class="number">44</td>
    			<td class="reference"><a name="fn44"></a>Privacy by Design: Current Practises in Estonia, India, and Austria, World Bank Group, 2018, <a href="https://id4d.worldbank.org/sites/id4d.worldbank.org/files/PrivacyByDesign_112918web.pdf" target="_blank"><em>https://id4d.worldbank.org/sites/id4d.worldbank.org/files/PrivacyByDesign_112918web.pdf</em></a>, [“ID4D WB”] 5.&nbsp;&nbsp;<span class="internal-nav"><a href="#ref44">&uarr;</em></a></span></td>
			  </tr>
  			  <tr>
    			<td class="number">45</td>
    			<td class="reference"><a name="fn45"></a>OECD Principles, <em>supra</em>; Justice Shah Report, <em>supra</em>, 27.&nbsp;&nbsp;<span class="internal-nav"><a href="#ref45">&uarr;</em></a></span></td>
			  </tr>
  			  <tr>
    			<td class="number">46</td>
    			<td class="reference"><a name="fn46"></a>Accountability: A Compendium for Stakeholders, The Centre for Information Policy Leadership, 2011, <a href="http://informationaccountability.org/wp-content/uploads/Centre-Accountability-Compendium.pdf" target="_blank"><em>http://informationaccountability.org/wp-content/uploads/Centre-Accountability-Compendium.pdf</em></a>, at 3.&nbsp;&nbsp;<span class="internal-nav"><a href="#ref46">&uarr;</em></a></span></td>
			  </tr>
  			  <tr>
    		    <td class="number">47</td>
    			<td class="reference"><a name="fn47"></a>For a detailed discussion on ex-ante and ex-post accountability, see Vrinda Bhandari and Renuka Sane, NLSIR, <em>supra</em>, 13.&nbsp;&nbsp;<span class="internal-nav"><a href="#ref47">&uarr;</em></a></span></td>
			  </tr>
  			  <tr>
    			<td class="number">48</td>
    			<td class="reference"><a name="fn48"></a>AccessNow, <em>supra</em>, 25.&nbsp;&nbsp;<span class="internal-nav"><a href="#ref48">&uarr;</em></a></span></td>
			  </tr>
  			  <tr>
    			<td class="number">49</td>
    			<td class="reference"><a name="fn49"></a>See the observations made by Chandachud J. in his dissent in <em>Aadhaar Judgment</em>, para 1539.5 (Chandrachud J). See also NLSIR, <em>supra</em>.&nbsp;&nbsp;<span class="internal-nav"><a href="#ref49">&uarr;</em></a></span></td>
			  </tr>
  			  <tr>
    			<td class="number">50</td>
    			<td class="reference"><a name="fn50"></a>T.H.A. Wisman, "Purpose and function creep by design: Transforming the face of surveillance through the Internet of Things", <em>European Journal of Law and Technology</em>, Vol. 4, No. 2 (2013), <a href="http://ejlt.org/article/view/192/379#_ftnref11" target="_blank"><em>http://ejlt.org/article/view/192/379#_ftnref11</em></a>; M. Granger Morgan and Elaine Newton, “Protecting Public Anonymity”, <em>21 Issues in Science and Technology</em> (2004).&nbsp;&nbsp;<span class="internal-nav"><a href="#ref50">&uarr;</em></a></span></td>
			  </tr>
  			  <tr>
    			<td class="number">51</td>
    			<td class="reference"><a name="fn51"></a>Nancy YueLiu, <em>Bio-Privacy: Privacy Regulation and the Challenge of Biometrics</em> (Routledge, 2012), 72-73 [“Liu”].&nbsp;&nbsp;<span class="internal-nav"><a href="#ref51">&uarr;</em></a></span></td>
			  </tr>
  			  <tr>
    			<td class="number">52</td>
    			<td class="reference"><a name="fn52"></a><em>Vinod Kumar v. Ashok Kumar Gandhi</em>, 1 SCC 1, (2019) para 1357.&nbsp;&nbsp;<span class="internal-nav"><a href="#ref52">&uarr;</em></a></span></td>
			  </tr>
  			  <tr>
    			<td class="number">53</td>
    			<td class="reference"><a name="fn53"></a><em>Leander v Sweden</em>, ECHR 4, (1987) para 48; <em>MK v France</em>, ECHR 341 (2013); <em>S & Marper v. UK</em>, ECHR 1581, (2008), para 67.&nbsp;&nbsp;<span class="internal-nav"><a href="#ref53">&uarr;</em></a></span></td>
			  </tr>
  			  <tr>
    			<td class="number">54</td>
    			<td class="reference"><a name="fn54"></a><em>Amann v. Switzerland</em>, ECHR 88 (2000), para 69.&nbsp;&nbsp;<span class="internal-nav"><a href="#ref54">&uarr;</em></a></span></td>
			  </tr>
  			  <tr>
    			<td class="number">55</td>
    			<td class="reference"><a name="fn55"></a><em>Puttaswamy, supra</em>, paras 311, 328 (Chandrachud J.), 640 (Kaul J.)&nbsp;&nbsp;<span class="internal-nav"><a href="#ref55">&uarr;</em></a></span></td>
			  </tr>
  			  <tr>
    			<td class="number">56</td>
    			<td class="reference"><a name="fn56"></a><em>S & Marper, supra</em>, para 101; <em>MK v France, supra</em>, para 33.&nbsp;&nbsp;<span class="internal-nav"><a href="#ref56">&uarr;</em></a></span></td>
			  </tr>
  			  <tr>
    			<td class="number">57</td>
    			<td class="reference"><a name="fn57"></a>Steven Greer. <em>The exceptions to Articles 8 to 11 of the European Convention on Human Rights.</em> Vol. 88. Council of Europe, 1997, <a href="https://www.echr.coe.int/LibraryDocs/DG2/HRFILES/DG2-EN-HRFILES-15(1997).pdf" target="_blank"><em>https://www.echr.coe.int/LibraryDocs/DG2/HRFILES/DG2-EN-HRFILES-15(1997).pdf</em></a>, at 15.&nbsp;&nbsp;<span class="internal-nav"><a href="#ref57">&uarr;</em></a></span></td>
			  </tr>
  			  <tr>
    			<td class="number">58</td>
    			<td class="reference"><a name="fn58"></a><em>MK v France, supra</em>, para 40.&nbsp;&nbsp;<span class="internal-nav"><a href="#ref58">&uarr;</em></a></span></td>
			  </tr>
  			  <tr>
    			<td class="number">59</td>
    			<td class="reference"><a name="fn59"></a><em>Puttaswamy, supra</em>, paras 310, 325, 638, 639.&nbsp;&nbsp;<span class="internal-nav"><a href="#ref59">&uarr;</em></a></span></td>
			  </tr>
  			  <tr>
    			<td class="number">60</td>
    			<td class="reference"><a name="fn60"></a><em>Aadhaar Judgment, supra</em>, paras 319, 494, 511.5 (Sikri J.)&nbsp;&nbsp;<span class="internal-nav"><a href="#ref60">&uarr;</em></a></span></td>
			  </tr>
  			  <tr>
    			<td class="number">61</td>
    			<td class="reference"><a name="fn61"></a>1 SCR 103 (1968).&nbsp;&nbsp;<span class="internal-nav"><a href="#ref61">&uarr;</em></a></span></td>
			  </tr>
  			  <tr>
    			<td class="number">62</td>
    			<td class="reference"><a name="fn62"></a><em>Robinson, Julian v. The Attorney General of Jamaica</em> (2019) JMFC Full 04 [“Robinson”]&nbsp;&nbsp;<span class="internal-nav"><a href="#ref62">&uarr;</em></a></span></td>
			  </tr>
  			  <tr>
    			<td class="number">63</td>
    			<td class="reference"><a name="fn63"></a><em>Robinson, supra</em>, para 247(B)(49).&nbsp;&nbsp;<span class="internal-nav"><a href="#ref63">&uarr;</em></a></span></td>
			  </tr>
  			  <tr>
    			<td class="number">64</td>
    			<td class="reference"><a name="fn64"></a>Principle 5, Necessity and Proportionality Principles, <em>International Principles on the Application of Human Rights to Communication Surveillance</em> (May, 2014), <a href="https://necessaryandproportionate.org/principles#principle5" target="_blank"><em>https://necessaryandproportionate.org/principles#principle5</em></a>.&nbsp;&nbsp;<span class="internal-nav"><a href="#ref64">&uarr;</em></a></span></td>
			  </tr>
  			  <tr>
    			<td class="number">65</td>
    			<td class="reference"><a name="fn65"></a>See also <em>Robinson, supra</em>, para 247(B)(56).&nbsp;&nbsp;<span class="internal-nav"><a href="#ref65">&uarr;</em></a></span></td>
			  </tr>
			  <tr>
    			<td class="number">66</td>
    			<td class="reference"><a name="fn66"></a>AccessNow, <em>supra</em>, 31.&nbsp;&nbsp;<span class="internal-nav"><a href="#ref66">&uarr;</em></a></span></td>
			  </tr>
			  <tr>
    			<td class="number">67</td>
    			<td class="reference"><a name="fn67"></a>Committee of Experts under the Chairmanship of Justice B.N. Srikrishna (2018) <a href="https://www.meity.gov.in/writereaddata/files/Data_Protection_Committee_Report.pdf" target="_blank"><em>https://www.meity.gov.in/writereaddata/files/Data_Protection_Committee_Report.pdf</em></a>, 53.&nbsp;&nbsp;<span class="internal-nav"><a href="#ref67">&uarr;</em></a></span></td>
			  </tr>
  			  <tr>
    			<td class="number">68</td>
    			<td class="reference"><a name="fn68"></a>White Paper of the Committee of Experts on a Data Protection Framework for India (2018), <a href="https://meity.gov.in/white-paper-data-protection-framework-india-public-comments-invited" target="_blank"><em>https://meity.gov.in/white-paper-data-protection-framework-india-public-comments-invited</em></a>, 104-105.&nbsp;&nbsp;<span class="internal-nav"><a href="#ref68">&uarr;</em></a></span></td>
			  </tr>
              <tr>
    			<td class="number">69</td>
    			<td class="reference"><a name="fn69"></a>See also Justice AP Shah Report, <em>supra</em>, 24; Debbie McElHill, “GDPR Data Retention Quick Guide”, <em>Data Protection Network</em> <a href="https://www.dpnetwork.org.uk/gdpr-data-retention-guide/" target="_blank"><em>https://www.dpnetwork.org.uk/gdpr-data-retention-guide/</em></a>.&nbsp;&nbsp;<span class="internal-nav"><a href="#ref69">&uarr;</em></a></span></td>
			  </tr>
			  <tr>
    			<td class="number">70</td>
    			<td class="reference"><a name="fn70"></a><em>S & Marper, supra</em>, paras 107, 114, 119.&nbsp;&nbsp;<span class="internal-nav"><a href="#ref70">&uarr;</em></a></span></td>
			  </tr>
			  <tr>
    			<td class="number">71</td>
    			<td class="reference"><a name="fn71"></a>Anmol Somanchi et al, “Well Done ABBA?,” 52(7) <em>EPW</em> (2017) <a href="https://www.epw.in/journal/2017/7/web-exclusives/well-done-abba.html" target="_blank"><em>https://www.epw.in/journal/2017/7/web-exclusives/well-done-abba.html</em></a>.&nbsp;&nbsp;<span class="internal-nav"><a href="#ref71">&uarr;</em></a></span></td>
			  </tr>
			  <tr>
    			<td class="number">72</td>
    			<td class="reference"><a name="fn72"></a>Geeta Pillai, “Need internet to buy PDS rations? Go climb a tree,” <em>The Times of India</em>, March 3, 2017, <a href="https://timesofindia.indiatimes.com/india/need-internet-to-buy-pds-rations-go-climb-a-tree/articleshow/57437975.cms" target="_blank"><em>https://timesofindia.indiatimes.com/india/need-internet-to-buy-pds-rations-go-climb-a-tree/articleshow/57437975.cms</em></a>.&nbsp;&nbsp;<span class="internal-nav"><a href="#ref72">&uarr;</em></a></span></td>
			  </tr>
			  <tr>
    			<td class="number">73</td>
    			<td class="reference"><a name="fn73"></a>Staff, “In Telangana, worn out fingerprints key reason behind 36% Aadhaar verification failure in key govt. scheme:Report,” <em>HuffPost</em>, April 7, 2017 <a href="https://www.huffingtonpost.in/2017/04/07/in-telangana-worn-out-fingerprints-behind-a-whopping-36-authen_a_22029773/?guccounter=1" target="_blank"><em>https://www.huffingtonpost.in/2017/04/07/in-telangana-worn-out-fingerprints-behind-a-whopping-36-authen_a_22029773/?guccounter=1</em></a>.&nbsp;&nbsp;<span class="internal-nav"><a href="#ref73">&uarr;</em></a></span></td>
			  </tr>
			  <tr>
    			<td class="number">74</td>
    			<td class="reference"><a name="fn74"></a>Gaurav Bhatnagar, “Testimonies Reveal how Aadhaar has Brought Pain, Exclusion to Poor,” <em>The Wire</em>, March 15, 2018, <a href="https://thewire.in/government/aadhaar-right-to-food-pain-exclusion" target="_blank"><em>https://thewire.in/government/aadhaar-right-to-food-pain-exclusion</em></a>.&nbsp;&nbsp;<span class="internal-nav"><a href="#ref74">&uarr;</em></a></span></td>
			  </tr>
			  <tr>
    			<td class="number">75</td>
    			<td class="reference"><a name="fn75"></a>Jahnavi Sen, “In Rural Jharkhand, Aadhaar Link to Welfare Schemes is Excluding the Most Needy” <em>The Wire</em>, September 26, 2018, <a href="https://thewire.in/government/jharkhand-aadhaar-pds-pensions" target="_blank"><em>https://thewire.in/government/jharkhand-aadhaar-pds-pensions</em></a>.&nbsp;&nbsp;<span class="internal-nav"><a href="#ref75">&uarr;</em></a></span></td>
			  </tr>
			  <tr>
    			<td class="number">76</td>
    			<td class="reference"><a name="fn76"></a>Subhashis Banerjee, Subodh Sharma, “An Offline Alternative for Aadhaar-based Authentication,” <em>Ideas for India</em>, September 24, 2018, <a href="https://www.ideasforindia.in/topics/productivity-innovation/an-%20offline-alternative-for-aadhaar-based-biometric-authentication.html" target="_blank"><em>https://www.ideasforindia.in/topics/productivity-innovation/an-%20offline-alternative-for-aadhaar-based-biometric-authentication.html</em></a>; Reetika Khera, “Aadhaar Bill Debate” Ideas for Change, <a href="https://www.ideasforindia.in/templates/i4ihome/images/author/Aadhaar-Bill-Debate-Reetika-Khera.pdf" target="_blank"><em>https://www.ideasforindia.in/templates/i4ihome/images/author/Aadhaar-Bill-Debate-Reetika-Khera.pdf</em></a>.&nbsp;&nbsp;<span class="internal-nav"><a href="#ref76">&uarr;</em></a></span></td>
			  </tr>
			  <tr>
    			<td class="number">77</td>
    			<td class="reference"><a name="fn77"></a>Olivia White et al., <em>Digital Identification: a Key to Inclusive Growth</em> (McKinsey Global Institute 2019) 7, <a href="https://www.mckinsey.com/featured-insights/innovation-and-growth/the-value-of-digital-id-for-the-global-economy-and-society" target="_blank"><em>https://www.mckinsey.com/featured-insights/innovation-and-growth/the-value-of-digital-id-for-the-global-economy-and-society</em></a> [“McKinsey”]&nbsp;&nbsp;<span class="internal-nav"><a href="#ref77">&uarr;</em></a></span></td>
              </tr>	
			  <tr>
    			<td class="number">78</td>
    			<td class="reference"><a name="fn78"></a><em>Robinson, supra</em>, 205.&nbsp;&nbsp;<span class="internal-nav"><a href="#ref78">&uarr;</em></a></span></td>
			  </tr>
			  <tr>
    			<td class="number">79</td>
    			<td class="reference"><a name="fn79"></a>AccessNow, <em>supra</em>, 23-24.&nbsp;&nbsp;<span class="internal-nav"><a href="#ref79">&uarr;</em></a></span></td>
			  </tr>
			  <tr>
    			<td class="number">80</td>
    			<td class="reference"><a name="fn80"></a><em>Robinson, supra</em>, para 247(B)(19), (48), (52), 349.&nbsp;&nbsp;<span class="internal-nav"><a href="#ref80">&uarr;</em></a></span></td>
			  </tr>
			  <tr>
    			<td class="number">81</td>
    			<td class="reference"><a name="fn81"></a><em>Robinson, supra</em>, para 237.&nbsp;&nbsp;<span class="internal-nav"><a href="#ref81">&uarr;</em></a></span></td>
			  </tr>
			  <tr>
    			<td class="number">82</td>
    			<td class="reference"><a name="fn82"></a>McKinsey, <em>supra</em>.&nbsp;&nbsp;<span class="internal-nav"><a href="#ref82">&uarr;</em></a></span></td>
			  </tr>
			  <tr>
    			<td class="number">83</td>
    			<td class="reference"><a name="fn83"></a>Jedidiah Bracy, “Demystifying the Risk Based Approach” <em>The Privacy Adviser</em>, April 30, 2014 <a href="https://iapp.org/news/a/demystifying-the-risk-based-approach/" target="_blank"><em>https://iapp.org/news/a/demystifying-the-risk-based-approach/</em></a>.&nbsp;&nbsp;<span class="internal-nav"><a href="#ref83">&uarr;</em></a></span></td>
			  </tr>
			  <tr>
    			<td class="number">84</td>
    			<td class="reference"><a name="fn84"></a>CNIL, Methodology for Risk Management (2012) 7, <a href="https://www.cnil.fr/sites/default/files/typo/document/CNIL-ManagingPrivacyRisks-Methodology.pdf" target="_blank"><em>https://www.cnil.fr/sites/default/files/typo/document/CNIL-ManagingPrivacyRisks-Methodology.pdf</em></a>, [“CNIL”]. &nbsp;&nbsp;<span class="internal-nav"><a href="#ref84">&uarr;</em></a></span></td>
			  </tr>
			  <tr>
    			<td class="number">85</td>
    			<td class="reference"><a name="fn85"></a>Fred Cate, “The Failure of Fair Information Practice Principles” in Winn, Jane K., ed. Consumer Protection in the Age of the 'Iinformation Economy'. London: Routledge, 2016.&nbsp;&nbsp;<span class="internal-nav"><a href="#ref85">&uarr;</em></a></span></td>
			  </tr>
			  <tr>
    			<td class="number">86</td>
    			<td class="reference"><a name="fn86"></a>CNIL, <em>supra</em>, at 8.&nbsp;&nbsp;<span class="internal-nav"><a href="#ref86">&uarr;</em></a></span></td>
			  </tr>
  			  <tr>
    			<td class="number">87</td>
    			<td class="reference"><a name="fn87"></a>AccessNow, <em>supra</em>, at 31.&nbsp;&nbsp;<span class="internal-nav"><a href="#ref87">&uarr;</em></a></span></td>
			  </tr>
			  <tr>
    			<td class="number">89</td>
    			<td class="reference"><a name="fn89"></a>Dave Birch et al., “Digital Identity: Issue Analysis”, June 8, 2016, <a href="http://www.chyp.com/wp-content/uploads/2016/07/Digital-Identity-Issue-Analysis-Report.pdf" target="_blank"><em>http://www.chyp.com/wp-content/uploads/2016/07/Digital-Identity-Issue-Analysis-Report.pdf</em></a>.&nbsp;&nbsp;<span class="internal-nav"><a href="#ref89">&uarr;</em></a></span></td>
			  </tr>
  			  <tr>
    			<td class="number">90</td>
    			<td class="reference"><a name="fn90"></a>National Research Council in Washington DC Report, “Biometric Recognition: Challenges and Opportunities”, 2010, <a href="https://dataprivacylab.org/TIP/2011sept/Biometric.pdf" target="_blank"><em>https://dataprivacylab.org/TIP/2011sept/Biometric.pdf</em></a>, 1.&nbsp;&nbsp;<span class="internal-nav"><a href="#ref90">&uarr;</em></a></span></td>
			  </tr>
			  <tr>
    			<td class="number">91</td>
    			<td class="reference"><a name="fn91"></a>ID4D WB, <em>supra</em>, 1; Mckinsey, <em>supra</em>, vi.&nbsp;&nbsp;<span class="internal-nav"><a href="#ref91">&uarr;</em></a></span></td>
			  </tr>
  			  <tr>
    			<td class="number">92</td>
    			<td class="reference"><a name="fn92"></a><em>Robinson, supra</em>, para 247(B)(48), (53). See also Liu, <em>supra</em>, 36-54.&nbsp;&nbsp;<span class="internal-nav"><a href="#ref92">&uarr;</em></a></span></td>
			  </tr>
  			  <tr>
    			<td class="number">93</td>
    			<td class="reference"><a name="fn93"></a>“Reducing False Positives without Increasing Regulatory Risks,” Oracle, last accessed August 1, 2019 <a href="https://www.oracle.com/technetwork/middleware/ows/documentation/ows-reducing-false-positives-wp-1864957.pdf" target="_blank"><em>https://www.oracle.com/technetwork/middleware/ows/documentation/ows-reducing-false-positives-wp-1864957.pdf</em></a> (webpage discontinued).&nbsp;&nbsp;<span class="internal-nav"><a href="#ref93">&uarr;</em></a></span></td>
			  </tr>
  			  <tr>
    			<td class="number">94</td>
    			<td class="reference"><a name="fn94"></a>ID4D WB, <em>supra</em>, 2.&nbsp;&nbsp;<span class="internal-nav"><a href="#ref94">&uarr;</em></a></span></td>
			  </tr>
  			  <tr>
    			<td class="number">95</td>
    			<td class="reference"><a name="fn95"></a>Nikhil Pahwa, <em>supra</em>.&nbsp;&nbsp;<span class="internal-nav"><a href="#ref95">&uarr;</em></a></span></td>
			  </tr>
  			  <tr>
    			<td class="number">96</td>
    			<td class="reference"><a name="fn96"></a>Nikhil Pahwa, <em>supra</em>.&nbsp;&nbsp;<span class="internal-nav"><a href="#ref96">&uarr;</em></a></span></td>
			  </tr>
  			  <tr>
    			<td class="number">97</td>
    			<td class="reference"><a name="fn97"></a>ID4D WB, <em>supra</em>, 18.&nbsp;&nbsp;<span class="internal-nav"><a href="#ref97">&uarr;</em></a></span></td>
			  </tr>
  			  <tr>
    			<td class="number">98</td>
    			<td class="reference"><a name="fn98"></a>AccessNow, <em>supra</em>, 9; Aili Vahatla, “Estonia Cancels Security Certificates of 11,100 electronic ID cards”, <em>ERR News</em>, June 1, 2018, <a href="https://news.err.ee/836259/estonia-cancels-security-certificates-of-11-100-electronic-id-cards" target="_blank"><em>https://news.err.ee/836259/estonia-cancels-security-certificates-of-11-100-electronic-id-cards</em></a>.&nbsp;&nbsp;<span class="internal-nav"><a href="#ref98">&uarr;</em></a></span></td>
			  </tr>
  			  <tr>
    			<td class="number">99</td>
    			<td class="reference"><a name="fn99"></a>“What we learned from the eID card security risk?,” e-estonia,  last accessed January 22, 2019, <a href="https://e-estonia.com/card-security-risk/" target="_blank"><em>https://e-estonia.com/card-security-risk/</em></a>.&nbsp;&nbsp;<span class="internal-nav"><a href="#ref99">&uarr;</em></a></span></td>
			  </tr>
			</table>
        <p>&nbsp;</p>
        <p>&nbsp;</p>
      </div>
  </div>
  <!-- Footer -->
  <div class="footer">	
    <div class="ui container four column stackable grid">
      <div class="six wide column">
        <h1>Digital Identities: Design and Uses</h1>
        <p>This website presents research undertaken by <a href="http://cis-india.org/" target="_blank">the Centre for Internet and Society, India</a> on appropriate design choices for digital identity frameworks, and their implications for both the sustainable development agenda as well for civil, social and economic rights. This research is supported by a grant from <a href="https://www.omidyar.com/" target="_blank">Omidyar Network</a>.</p>
        <p>Copyright: <a href="http://cis-india.org/" target="_blank">CIS, India</a>, 2019<br />License: <a href="https://creativecommons.org/licenses/by/4.0/" target="_blank">CC BY 4.0 International</a></p>
        <p>Built using <a href="https://semantic-ui.com/" target="_blank">Semantic UI</a> and <a href="https://web.hypothes.is/" target="_blank">Hypothes.is</a><br/><a href="https://fonts.google.com/specimen/Fira+Sans" target="_blank">Fira Sans</a> and <a href="https://fonts.google.com/specimen/IBM+Plex+Serif" target="_blank">IBM Plex Serif</a> by <a href="https://fonts.google.com/" target="_blank">Google Fonts</a><br/>Social media icons by <a href="https://fontawesome.com/" target="_blank">Font Awesome</a><br/>Hosted on <a href="https://github.com/digitalid-design/digitalid-design.github.com" target="_blank">GitHub</a></p>
      </div>
      <div class="three wide column team">
        <h1>Team</h1>
        <p>Akash Sheshadri</p>
        <p>Amber Sinha</p>
        <p>Pooja Saxena</p>
        <p>Saumyaa Naidu</p>
        <p>Shruti Trikanad</p>
        <p>Yesha Tshering Paul</p>
      </div>
      <div class="three wide column contributors">
        <h1>Contributors</h1>
        <p>Kushang Mishra</p>
        <p>Prakriti Singh</p>
        <p>Sumandro Chattapadhyay</p>
        <p>Sunil Abraham</p>
        <p>Vrinda Bhandari</p>
      </div>
      <div class="four wide column">
        <div>
          <a href="https://cis-india.org/" target="_blank" style="border-bottom: 0px solid"><img src="img/logo.png" alt="The Centre for Internet and Society, India" class="logo" /></a>
        </div>
        <div class="icons">
          <a href="https://twitter.com/cis_india" target="_blank"><i class="fab fa-twitter fa-lg"></i></a> <a href="https://www.instagram.com/cis.india/" target="_blank"><i class="fab fa-instagram fa-lg"></i></a> <a href="https://www.youtube.com/channel/UC0SLNXQo9XQGUE7Enujr9Ng" target="_blank"><i class="fab fa-youtube fa-lg"></i></a></p>
        </div>
      </div>
    </div>
  </div>
  <!-- Hypothesis -->
  <script type="application/json" class="js-hypothesis-config">
    {"showHighlights": false}
  </script>
  <script src="https://hypothes.is/embed.js" async></script>
</body>
</html>
